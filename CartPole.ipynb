{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011f37c4-77f2-41a2-a1c8-a83fca3fbc0c",
   "metadata": {},
   "source": [
    "## Q learning with the CartPole-v1 using Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d7c09",
   "metadata": {},
   "source": [
    "For a detailed description of the cartpole env, refer to [this](https://www.gymlibrary.dev/environments/classic_control/cart_pole/) site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717983ec-9919-47e4-af5b-dc3a0af603a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3833be8a-e61d-4d88-b11c-a0445c743e9a",
   "metadata": {},
   "source": [
    "### Configuring the display using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b99802-d19f-4637-8c63-24104cc632c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c9de8",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "#### Action space\n",
    "\n",
    "The action is an `ndarray` with shape `(1,)` which can take values {0, 1} indicating the direction of the fixed force the cart is pushed with.\n",
    "\n",
    "#### State Space\n",
    "\n",
    "The observation is an `ndarray` with shape `(4,)` with the values corresponding to the following positions and velocities:\n",
    "\n",
    "| Num |      Observation      |         Min         |        Max        |   |\n",
    "|:---:|:---------------------:|:-------------------:|:-----------------:|---|\n",
    "| 0   | Cart Position         | -4.8                | 4.8               |   |\n",
    "| 1   | Cart Velocity         | -Inf                | Inf               |   |\n",
    "| 2   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |   |\n",
    "| 3   | Pole Angular Velocity | -Inf                | Inf               |   |\n",
    "\n",
    "#### Rewards\n",
    "\n",
    "Since the goal is to keep the pole upright for as long as possible, a reward of `+1` for every step taken, including the termination step, is allotted. The threshold for rewards is `475` for v1.\n",
    "\n",
    "#### Starting State\n",
    "\n",
    "All observations are assigned a uniformly random value in (-0.05, 0.05)\n",
    "\n",
    "#### Episode\n",
    "\n",
    "The episode ends if any one of the following occurs:\n",
    "\n",
    "- `Termination`: Pole Angle is greater than ±12°</li>\n",
    "- `Termination`: Cart Position is greater than ±2.4 (center of the cart reaches the edge of the display)</li>\n",
    "- `Truncation`: Episode length is greater than 500 (200 for v0)</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459aeb6",
   "metadata": {},
   "source": [
    "### Discretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833cbce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import math\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a044e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = ( 6 , 12 )\n",
    "lower_bounds = [ env.observation_space.low[2], -math.radians(50) ]\n",
    "upper_bounds = [ env.observation_space.high[2], math.radians(50) ]\n",
    "\n",
    "def discretizer( _ , __ , angle, pole_velocity ) -> Tuple[int,...]:\n",
    "    \"\"\"Convert continues state intro a discrete state\"\"\"\n",
    "    est = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "    est.fit([lower_bounds, upper_bounds ])\n",
    "    return tuple(map(int,est.transform([[angle, pole_velocity]])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77431b36",
   "metadata": {},
   "source": [
    "#### Define the policy\n",
    "<!-- $\\epsilon$ / $|A|$ + 1 - $\\epsilon$ --- $max_{a}Q(s, a)$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f59a582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy( state : tuple , eps = 0.1):\n",
    "    \"\"\"\n",
    "    Epsilon greedy policy\n",
    "    Choose the next action as follows\n",
    "    eps / |A| + (1 - eps) --> greedy best\n",
    "    eps / |A|             --> others\n",
    "    \"\"\"\n",
    "    return np.argmax(Q_table[state]) if np.random.random() <= 1 - eps else np.random.randint(len(Q_table[state]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7693c78",
   "metadata": {},
   "source": [
    "#### Update q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fdc715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_Q_value( reward : float ,  new_state : tuple , discount_factor=1 ) -> float:\n",
    "    \"\"\"Here we simply do a max on the best action possible from the next state\"\"\"\n",
    "    future_optimal_value = np.max(Q_table[new_state])\n",
    "    learned_value = reward + discount_factor * future_optimal_value\n",
    "    return learned_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fda0cc",
   "metadata": {},
   "source": [
    "#### Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f92fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(n : int) -> float  :\n",
    "    \"\"\"Decaying learning rate\"\"\"\n",
    "    return 1 / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26552054-8d8c-4a21-8620-b7627cf862d8",
   "metadata": {},
   "source": [
    "### The runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f61a5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_rgb = lambda rendered_list: np.array(rendered_list).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b21350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 5\n",
    "\n",
    "def Q_learning(environment, discretizer, Q_table, n_episodes = 5):\n",
    "    for e in range(n_episodes):\n",
    "\n",
    "        # Discretize state into buckets\n",
    "        current_state = discretizer(*environment.reset())\n",
    "        img = plt.imshow(env_rgb(environment.render()))\n",
    "\n",
    "        iters = 1\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Choose the current action using eps greedy policy\n",
    "            action = policy(current_state) # exploit\n",
    "\n",
    "            # Take a step in the enviroment\n",
    "            obs, reward, done, _, _ = environment.step(action)\n",
    "            new_state = discretizer(*obs)\n",
    "\n",
    "            # Update the display\n",
    "            plt.title(f\"Episode no: {e+1} Iteration no: {iters}\")       \n",
    "            img.set_data(env_rgb(environment.render()))\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True) \n",
    "\n",
    "            # Update the q-table\n",
    "            lr = learning_rate(e + 1)\n",
    "            learnt_value = new_Q_value(reward , new_state)\n",
    "            old_value = Q_table[current_state][action]\n",
    "            Q_table[current_state][action] = (1-lr)*old_value + lr*learnt_value\n",
    "\n",
    "            # Iterative updates\n",
    "            current_state = new_state\n",
    "            iters += 1\n",
    "    return Q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895465a-4587-4813-9eb2-649d60f3ad92",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4473464c-d733-4ed6-8552-52cb4b96031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episodes(environment, n_episodes, Q_res):\n",
    "    wins = 0\n",
    "    total_reward = 0\n",
    "    for episode in range(n_episodes):\n",
    "        terminated = False\n",
    "        state = environment.reset()\n",
    "        state = discretizer(*state)\n",
    "        while not terminated:\n",
    "            # Select best action to perform in a current state\n",
    "            action = np.argmax(Q_res[state])\n",
    "            # Perform an action an observe how environment acted in response\n",
    "            next_state, reward, terminated, info, _ = environment.step(action)\n",
    "            # Summarize total reward\n",
    "            total_reward += reward\n",
    "            # Update current state\n",
    "            next_state = discretizer(*next_state)\n",
    "            state = next_state\n",
    "\n",
    "    average_reward = total_reward / n_episodes\n",
    "    return total_reward, average_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dc412a1-ea34-47c8-972b-42affb47c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = gym.make('CartPole-v1', render_mode=\"rgb_array\", new_step_api=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dc4e899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q_table = np.zeros((*n_bins, env.action_space.n))\n",
    "N_EPISODES = 5\n",
    "Q_result = Q_learning(environment, discretizer, Q_table, N_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca3297ea-6d5d-43f7-9127-4dbb202563ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward over 5 episodes = 10.2 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_reward, average_reward = play_episodes(environment, n_episodes, Q_result)\n",
    "print(f'Average reward over {n_episodes} episodes = {average_reward} \\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
